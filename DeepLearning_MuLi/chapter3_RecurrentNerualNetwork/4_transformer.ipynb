{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844e1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-head attention\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "import math\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc18ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(128, 64, 512) \n",
    "# Batch Time（Sequence Length） Dimension(Embedding Dimention)(编码后的维度，想embeding映射到多少维度)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd87b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512 # 映射到QKV的多少维度\n",
    "n_head = 8 # 头数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29122e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass A:\\n    def method(self):\\n        print(\"A.method\")\\n\\nclass B(A):\\n    def method(self):\\n        print(\"B.method\")\\n        super().method()  # 调用A.method\\n\\nclass C(B):\\n    def method(self):\\n        print(\"C.method\")\\n        super(B, self).method()  # 直接跳过B，调用A.method！\\n        # 而 super().method() 会调用 B.method\\n\\n这个为什么会跳过B？\\n这个跳过B的原因是 super(B, self) 明确指定了从B之后开始查找MRO链。\\nMRO（方法解析顺序）C -> B -> A\\n1. super().method() 在C类中\\nclass C(B):\\n    def method(self):\\n        print(\"C.method\")\\n        super().method()  # 等价于 super(C, self).method()\\n\\n从C之后开始查找MRO链：[B, A]\\n\\n找到第一个有method的类：B\\n\\n所以调用 B.method()\\n\\n2. super(B, self).method() 在C类中\\nclass C(B):\\n    def method(self):\\n        print(\"C.method\")\\n        super(B, self).method()  # 明确指定跳过B\\n        \\n查找过程：\\n\\n从B之后开始查找MRO链：[A]\\n\\n直接跳过B\\n\\n找到下一个有method的类：A\\n\\n所以调用 A.method()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class A:\n",
    "    def method(self):\n",
    "        print(\"A.method\")\n",
    "\n",
    "class B(A):\n",
    "    def method(self):\n",
    "        print(\"B.method\")\n",
    "        super().method()  # 调用A.method\n",
    "\n",
    "class C(B):\n",
    "    def method(self):\n",
    "        print(\"C.method\")\n",
    "        super(B, self).method()  # 直接跳过B，调用A.method！\n",
    "        # 而 super().method() 会调用 B.method\n",
    "\n",
    "这个为什么会跳过B？\n",
    "这个跳过B的原因是 super(B, self) 明确指定了从B之后开始查找MRO链。\n",
    "MRO（方法解析顺序）C -> B -> A\n",
    "1. super().method() 在C类中\n",
    "class C(B):\n",
    "    def method(self):\n",
    "        print(\"C.method\")\n",
    "        super().method()  # 等价于 super(C, self).method()\n",
    "\n",
    "从C之后开始查找MRO链：[B, A]\n",
    "\n",
    "找到第一个有method的类：B\n",
    "\n",
    "所以调用 B.method()\n",
    "\n",
    "2. super(B, self).method() 在C类中\n",
    "class C(B):\n",
    "    def method(self):\n",
    "        print(\"C.method\")\n",
    "        super(B, self).method()  # 明确指定跳过B\n",
    "        \n",
    "查找过程：\n",
    "\n",
    "从B之后开始查找MRO链：[A]\n",
    "\n",
    "直接跳过B\n",
    "\n",
    "找到下一个有method的类：A\n",
    "\n",
    "所以调用 A.method()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7510d503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1749e-02, -3.0374e-02,  4.8668e-02,  ...,  4.9120e-02,\n",
       "          -7.1959e-02,  6.0836e-02],\n",
       "         [ 1.3038e-02, -1.5902e-03, -3.2350e-04,  ...,  3.4419e-02,\n",
       "          -8.1254e-02,  8.3808e-02],\n",
       "         [ 1.8813e-02, -1.3788e-02, -6.8165e-03,  ...,  4.0832e-02,\n",
       "          -8.4661e-02,  8.4138e-02],\n",
       "         ...,\n",
       "         [-1.4644e-02, -1.3101e-02,  8.0912e-03,  ...,  5.2369e-02,\n",
       "          -1.2297e-01,  6.4357e-02],\n",
       "         [ 1.6878e-02,  4.8485e-03,  1.2748e-02,  ...,  3.9039e-02,\n",
       "          -9.2022e-02,  5.5626e-02],\n",
       "         [ 1.7730e-03,  2.4077e-02,  2.6180e-02,  ...,  3.8056e-02,\n",
       "          -6.2393e-02,  8.5839e-02]],\n",
       "\n",
       "        [[ 6.2945e-02,  9.3349e-02, -4.4470e-02,  ...,  5.7741e-02,\n",
       "          -6.5188e-02,  1.2842e-03],\n",
       "         [ 2.9000e-02,  5.9636e-02, -3.2421e-02,  ...,  2.1193e-02,\n",
       "          -4.1963e-02, -1.4982e-02],\n",
       "         [ 1.9922e-02,  8.0316e-02, -5.2340e-02,  ...,  4.8672e-02,\n",
       "          -3.3632e-02, -1.3564e-02],\n",
       "         ...,\n",
       "         [ 5.6347e-02,  6.9132e-02, -2.2050e-02,  ...,  4.9355e-02,\n",
       "          -4.5953e-02, -3.6793e-03],\n",
       "         [ 5.8479e-02,  7.6695e-02, -4.0971e-02,  ...,  5.6998e-02,\n",
       "          -3.2862e-02, -1.6704e-02],\n",
       "         [ 1.3888e-02,  8.7441e-02, -2.7048e-02,  ...,  3.6534e-02,\n",
       "          -4.6688e-02, -1.5071e-02]],\n",
       "\n",
       "        [[ 2.3605e-02,  2.5121e-02, -1.4615e-02,  ...,  8.5188e-02,\n",
       "           3.9598e-02,  4.4066e-02],\n",
       "         [-5.1050e-03,  6.1746e-02, -6.0979e-02,  ...,  1.0262e-01,\n",
       "           4.5125e-02,  4.7611e-02],\n",
       "         [ 2.6106e-02,  4.2637e-02, -3.3308e-02,  ...,  1.1625e-01,\n",
       "           3.9803e-02,  5.3192e-02],\n",
       "         ...,\n",
       "         [ 3.0364e-02,  3.5640e-02, -6.0501e-02,  ...,  1.0923e-01,\n",
       "           4.1956e-02,  3.3387e-02],\n",
       "         [ 4.4532e-02,  7.6201e-02, -2.6002e-02,  ...,  8.7584e-02,\n",
       "           5.4694e-02,  3.2123e-02],\n",
       "         [ 3.9028e-02,  3.0363e-02, -4.3913e-02,  ...,  7.8399e-02,\n",
       "           3.8909e-02,  5.7724e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.3651e-02, -3.2367e-02, -5.5481e-02,  ...,  8.2740e-02,\n",
       "          -3.2331e-02,  3.7276e-02],\n",
       "         [-1.5597e-02, -2.2510e-02, -4.1849e-02,  ...,  1.1841e-01,\n",
       "          -3.4900e-02,  1.5010e-02],\n",
       "         [ 4.3240e-02, -1.6951e-02, -5.0680e-02,  ...,  1.2525e-01,\n",
       "          -3.2940e-02,  3.3594e-02],\n",
       "         ...,\n",
       "         [ 5.0295e-02, -2.2526e-02, -3.1440e-02,  ...,  1.0739e-01,\n",
       "          -3.4900e-02,  4.0852e-02],\n",
       "         [ 2.3764e-02, -4.3033e-02, -3.4372e-02,  ...,  1.0487e-01,\n",
       "          -4.6464e-02,  1.6414e-02],\n",
       "         [ 3.3717e-02, -3.3135e-02, -1.6069e-02,  ...,  1.0518e-01,\n",
       "          -3.7229e-02,  1.0206e-02]],\n",
       "\n",
       "        [[ 3.8776e-02,  4.9409e-02, -5.3834e-02,  ...,  3.9500e-02,\n",
       "          -1.9364e-02,  1.0789e-02],\n",
       "         [ 2.7012e-02,  3.1175e-02, -5.0271e-02,  ...,  5.9150e-02,\n",
       "           4.2772e-03,  2.4003e-02],\n",
       "         [ 4.9063e-02,  3.4655e-02, -6.0267e-02,  ...,  3.1260e-02,\n",
       "           2.4226e-03,  1.5611e-03],\n",
       "         ...,\n",
       "         [ 2.6278e-02,  4.5270e-02, -3.4458e-02,  ...,  3.3798e-02,\n",
       "           1.8160e-02,  2.9183e-03],\n",
       "         [ 1.8521e-02,  2.7792e-02, -8.6720e-02,  ...,  1.0364e-02,\n",
       "           3.3039e-03,  4.0759e-02],\n",
       "         [ 2.9833e-02,  1.6432e-02, -6.5421e-02,  ...,  3.7043e-02,\n",
       "           2.6946e-03,  1.8278e-02]],\n",
       "\n",
       "        [[ 6.5729e-02, -1.6301e-02, -5.0695e-02,  ..., -4.0710e-02,\n",
       "           1.2869e-05,  2.5804e-02],\n",
       "         [ 4.5923e-02,  1.4501e-02, -9.4394e-02,  ..., -4.6773e-02,\n",
       "          -9.7854e-03,  4.6972e-02],\n",
       "         [ 2.8851e-02, -1.2762e-02, -7.0738e-02,  ..., -3.7759e-02,\n",
       "          -9.8004e-03,  5.4806e-02],\n",
       "         ...,\n",
       "         [ 4.2036e-03, -3.0742e-02, -6.7194e-02,  ..., -1.3059e-02,\n",
       "          -2.8423e-02,  5.2603e-02],\n",
       "         [ 5.0919e-02, -3.5317e-02, -7.6187e-02,  ..., -2.9291e-02,\n",
       "          -4.0111e-04,  4.3360e-02],\n",
       "         [ 4.1950e-02, -2.1179e-03, -9.0754e-02,  ..., -6.1693e-02,\n",
       "          -1.2231e-02,  3.7670e-02]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHearAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        # 初始化QKV用于映射向量\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        # 因为是muti-head所以最后要做一个组合映射\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: Tensor, v: Tensor, mask = None):\n",
    "        batch, time, dimension = q.shape\n",
    "        n_d = self.d_model // self.n_head # 整除，相当于每个头被分到的注意力的维度\n",
    "        q, k, v = self.w_q(q),self.w_k(k), self.w_v(v)\n",
    "        # 原始q的形状可能是：(batch, time, d_model)，其中 d_model = n_head * n_d\n",
    "        # 理解q1，k1是行向量\n",
    "        q = q.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3) # head_维不能放在最后两维，因为要用于处理\n",
    "        k = k.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        v = v.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "\n",
    "        score = q @ k.transpose(2, 3) / math.sqrt(n_d) # 除以是为了方差更小好归一化\n",
    "        # 控制方差：点积的方差与 $d_k$ 成正比，除以 $\\sqrt{d_k}$ 使方差保持为1，稳定softmax：\n",
    "        # 防止softmax进入梯度极小的饱和区，改善梯度流：使训练更加稳定，防止梯度消失，\n",
    "        # 保持注意力分布合理：避免注意力过于集中在少数位置（变成近乎one-hot）\n",
    "        if mask is not None:\n",
    "            # mask = torch.tril(torch.ones(time, time, dtype=bool)) # 生成下三角矩阵 这里开始采用传进来的mask\n",
    "            score = score.masked_fill(mask == 0, float(\"-inf\")) # masked 注意力分数\n",
    "        \n",
    "        score_weight: Tensor = self.softmax(score) # softmax 自动对最后一维做，这里刚好需要列做softmax\n",
    "        output = score_weight @ v\n",
    "        # 把n_head和time再逆转回去\n",
    "        output = output.permute(0, 2, 1, 3).contiguous().view(batch, time, dimension)\n",
    "        # 连续内存（contiguous）\n",
    "        # view() 要求张量在内存中是连续的 因为它只是改变张量的\"视图\"，不复制数据\n",
    "        # reshape()可以替代该功能\n",
    "\n",
    "        output = self.w_combine(output)\n",
    "        return output\n",
    "    \n",
    "attention = MultiHearAttention(d_model, n_head)\n",
    "output = attention(X, X, X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c9f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token and position embedding\n",
    "\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__(vocab_size, d_model, padding_idx=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec418dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Embedding\n",
    "\n",
    "class PositionEmbedding(nn.Module):\n",
    "        def __init__(self, d_model, maxlen, device):\n",
    "            super().__init__()\n",
    "            self.encoding = torch.zeros(maxlen, d_model, device)\n",
    "            # 因为这个编码不需要梯度\n",
    "            self.encoding.requires_grad(False)\n",
    "\n",
    "            pos = torch.arange(0, maxlen, device=device)\n",
    "            pos = pos.float().unsqueeze(1) # 增加一个维度\n",
    "            # 生成2i的序列\n",
    "            _2i = torch.arange(0, d_model, step=2, device=device)\n",
    "            # self.encoding[:, start:stop:step]\n",
    "            self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model))) \n",
    "            self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "            # 相当是对位置从0-> Maxlen的位置进行编码，每个位置都是当前pos=i的一个512维的向量\n",
    "\n",
    "        def forward(self, x: Tensor):\n",
    "            seq_len = x.shape[1]\n",
    "            return self.encoding[:seq_len] # (seq_len, d_ model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1f37a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm (图像一般是BatchNorm)\n",
    "# 最核心的是可以减小显存的用量，比batch要的少所以可以减少显存用量\n",
    "# 相当于在做归一化的操作，需要参数\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-10):\n",
    "        super().__init__()\n",
    "        # 在做归一化的操作，需要参数，下列操作为默认\n",
    "        # 为什么需要gamma和beta？如果不加这两个参数，归一化会破坏网络学到的特征表示\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        mean = x.mean(-1, keepdim=True) # 是对最后一个维度 变成（batch_size, Sequence_len, d_model->1）\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        # 所以相当于对d_model维度做归一化\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out\n",
    "    \n",
    "# 归一化是必须的，但完全标准化的分布不一定是最优的。所以可以学习这个分布调整方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2026652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN Relu(xW1+b1)W2+b2\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1421240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Embedding\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, drop_prob, device):\n",
    "        super().__init__()\n",
    "        self.tok_emb = TokenEmbedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionEmbedding(d_model, max_len, device)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_emb = self.pos_emb(x)\n",
    "        tok_emb = self.tok_emb(x)\n",
    "        return self.dropout(pos_emb+tok_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33547945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHearAttention(d_model, n_head)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        _x = x\n",
    "        x = self.attention(x, x, x, mask)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + _x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab24ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "# decoder layer vs encoder layer\n",
    "# 带掩码的attention\n",
    "# cross-attention\n",
    "# encoder提供的是key, value, decoder提供querry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a4fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_module, ffn_hidden, n_head, drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHearAttention(d_model, n_head)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.cross_attention = MultiHearAttention(d_model, n_head)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, dec, enc, t_mask, s_mask):\n",
    "        # 两个掩码，一个是padding的掩码，一个是对未来信息的掩码\n",
    "        # t_mask下三角掩码, t_mask因果关系的掩码\n",
    "        # s_mask未知的掩码，不需要关注padding的信息\n",
    "        _x = dec\n",
    "        x = self.attention(dec, dec, dec, t_mask) #下三角掩码, t_mask因果关系的掩码\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        if enc is not None:\n",
    "            _x = x\n",
    "            x = self.cross_attention(x, enc, enc, s_mask)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.norm2(x + _x)\n",
    "\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "\n",
    "        x = self.dropout3(x)\n",
    "        x = self.norm3(x + _x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1fa566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, env_voc_size, max_len, d_model, ffn_hidden, n_head, n_layer, drop_prob, device):\n",
    "        super().__init__()\n",
    "        self.embedding = TransformerEmbedding(env_voc_size, d_model, max_len, drop_prob, device)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, ffn_hidden, n_head, drop_prob) for _ in range(n_layer)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, s_mask):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, s_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543dc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layer, drop_prob, device):\n",
    "        super().__init__()\n",
    "        self.embedding = TransformerEmbedding(dec_voc_size, d_model, max_len, drop_prob, device)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, ffn_hidden, n_head, drop_prob) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, dec_voc_size)\n",
    "\n",
    "    def forward(self, dec, enc, t_mask, s_mask):\n",
    "        dec = self.embedding(dec)\n",
    "        for layer in self.layers:\n",
    "            dec = layer(dec, enc, t_mask, s_mask)\n",
    "        dec = self.fc(dec)\n",
    "        return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "090be3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_pad_idx, trg_pad_idx, env_voc_size, dec_voc_size, max_len, d_model, n_heads, ffn_hidden, n_layers, drop_prob, device):\n",
    "        # 两个pad是输入的pad和decoder的pad的标示符的记录\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(env_voc_size, max_len, d_model, ffn_hidden, n_heads, n_layers, drop_prob, device)\n",
    "        self.decoder = Decoder(dec_voc_size, max_len, d_model, ffn_hidden, n_heads, n_layers, drop_prob, device)\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_pad_mask(self, q: Tensor, k: Tensor, pad_idx_q, pad_idx_k):\n",
    "        len_q, len_k = q.shape[1], k.shape[1]\n",
    "        # (Batch, Time, len_q, len_k) ne, not equal, 不等于pading符时为true\n",
    "        # q 应该是形状为 (batch_size, seq_len_q) 的序列索引, 而不是\n",
    "        # 这是序列索引经过嵌入层转换后的连续向量表示，每个整数索引被映射为一个d_model维的向量\n",
    "        # 形状是 (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # (Batch, Time, len_q, len_k)\n",
    "        q = q.ne(pad_idx_q).unsqueeze(1).unsqueeze(3) # 填充到四维\n",
    "        q = q.repeat(1, 1, 1, len_k) #\n",
    "\n",
    "        k = k.ne(pad_idx_k).unsqueeze(1).unsqueeze(2)\n",
    "        k = k.repeat(1, 1, len_q, 1) #\n",
    "\n",
    "        mask = q & k\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def make_casual_mask(self, q: Tensor, k: Tensor):\n",
    "        len_q, len_k = q.shape[1], k.shape[1]\n",
    "        mask = torch.tril(torch.ones(len_q, len_k)).type(torch.bool).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_pad_mask(src, src, self.src_pad_idx, self.src_pad_idx)\n",
    "        # decoder自己的因果mask\n",
    "        trg_mask = self.make_pad_mask(trg, trg, self.trg_pad_idx, self.trg_pad_idx) * self.make_casual_mask(trg, trg)\n",
    "        src_trg_mask = self.make_pad_mask(trg, src, self.trg_pad_idx, self.src_pad_idx)\n",
    "\n",
    "        enc = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc, trg_mask, src_trg_mask)\n",
    "        return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
